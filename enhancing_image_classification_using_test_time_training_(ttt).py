# -*- coding: utf-8 -*-
"""Enhancing Image Classification Using Test-Time-Training (TTT)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mSk9OY0PFnU0T7UZtRjMgPbvAk_rLGlQ

# Enhancing Image Classification Using Test-Time-Training (TTT)

# 0. Initialization

### a. Download necessary packages
"""

# originally, as you can see, we tried using openai for image generation but decided to use the hugging face
#!pip install requests
#!pip install --upgrade openai
#!openai migrate
#!pip install openai==0.28

"""### b. Library Imports"""

# Pytorch.
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import matplotlib.pyplot as plt

# evaluation metrics.
from sklearn import metrics
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score

# torchvision.
import torchvision
import torchvision.transforms as transforms
from torchvision import datasets, transforms
from torchvision.transforms import GaussianBlur
from torch.utils.data import DataLoader, random_split, Subset

# images.
from PIL import Image, ImageFilter, ImageEnhance

# kaggle.
import kagglehub

# plots.
import matplotlib.pyplot as plt
import seaborn as sns

# standard libraries.
import os
import numpy as np
import random
import shutil

# Chatpgpt Packages.
from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler

from io import BytesIO
import requests
from IPython.display import display
import time     # super important so we don't overwhelm with a lot of openai api calls!!!

"""# 1. Preprocess Data

### a. Define training and testing datasets
"""

# https://www.kaggle.com/datasets/borhanitrash/animal-image-classification-dataset
path = kagglehub.dataset_download("borhanitrash/animal-image-classification-dataset")
print("Path to dataset files:", path)

print(os.listdir(path + "/Animals"))

"""folder_path = os.path.join(path, "Animals", "train")
if os.path.exists(folder_path):
    shutil.rmtree(folder_path)
    print(f"Removed: {folder_path}")
else:
    print("Folder not found")

folder_path = os.path.join(path, "Animals", "test")
if os.path.exists(folder_path):
    shutil.rmtree(folder_path)
    print(f"Removed: {folder_path}")
else:
    print("Folder not found")
"""

dataset = datasets.ImageFolder(root = path + "/Animals")

print(os.listdir(path + "/Animals"))

train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
])

test_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_subset, test_subset = random_split(dataset, [train_size, test_size])

# Apply transformations to each subset
train_dataset = Subset(
    dataset=dataset,
    indices=train_subset.indices
)
train_dataset.dataset.transform = train_transforms

test_dataset = Subset(
    dataset=dataset,
    indices=test_subset.indices
)
test_dataset.dataset.transform = test_transforms

print(f"Train dataset size: {len(train_dataset)}")
print(f"Test dataset size: {len(test_dataset)}")

train_loader = DataLoader(train_dataset,
                          batch_size=32,
                          shuffle=True,
                          worker_init_fn=lambda worker_id: np.random.seed(42 + worker_id))

test_loader = DataLoader(test_dataset,
                         batch_size=32,
                         shuffle=False)

"""### b. Grab Shape of Images"""

IMAGE_SHAPE = tuple(train_dataset[0][0].shape)    # should be (3, 224, 224); refer to the code block above!
print("Image size: " + str(IMAGE_SHAPE))

"""### c. Visualizing *some*  Training and Testing Images"""

def show_images(images, labels, class_names, num_rows=4, num_cols=8):
    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 6))
    axes = axes.flatten()  # Flatten for easy iteration

    for i in range(num_rows * num_cols):
        if i >= len(images):  # Handle cases where batch size < num_rows*num_cols
            break
        img = images[i] / 2 + 0.5  # Unnormalize
        npimg = img.numpy().transpose((1, 2, 0))  # Convert tensor to image

        axes[i].imshow(npimg)
        axes[i].set_title(class_names[labels[i].item()], fontsize=8)  # Set label
        axes[i].axis("off")  # Hide axis

    plt.tight_layout()
    plt.show()

# Load a batch of training images
data_iter = iter(train_loader)
images, labels = next(data_iter)

# Show the images in a grid with labels
show_images(images, labels, dataset.classes, num_rows=4, num_cols=8)

"""# 2. Image Transformations

### a. Define Text-To-Image Model from Huggingface
"""

# from huggingface docs.
model_id = "stabilityai/stable-diffusion-2"
scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder="scheduler")
pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    scheduler=scheduler,
    torch_dtype=torch.float16
).to("cuda")

def generate_resized_image(prompt: str) -> Image.Image:
    image = pipe(prompt).images[0]
    return image.resize((224, 224), Image.LANCZOS)

"""### b. Visualize on a Single Image"""

images = [generate_resized_image("create a blurry version of a cat image apply a soft even blur effect to the entire picture so that the details are obscured and out of out the focus but the general shapes and colors remain visible.") for _ in range(3)]

plt.figure(figsize=(12, 4))
for i, img in enumerate(images):
    plt.subplot(1, 3, i + 1)
    plt.imshow(img)
    plt.axis("off")
    plt.title(f"Cat {i+1}")
plt.tight_layout()
plt.show()

images = [generate_resized_image("animated cat image") for _ in range(3)]

plt.figure(figsize=(12, 4))
for i, img in enumerate(images):
    plt.subplot(1, 3, i + 1)
    plt.imshow(img)
    plt.axis("off")
    plt.title(f"Cat {i+1}")
plt.tight_layout()
plt.show()

# Get the class names and their indices
class_to_idx = dataset.class_to_idx
idx_to_class = {v: k for k, v in class_to_idx.items()}
print(f"Class mapping: {class_to_idx}")

class TestImageDataset(Dataset):
    def __init__(self, original_dataset, idx_to_class, prompt_name, transform=None):
        self.original_dataset = original_dataset
        self.idx_to_class = idx_to_class
        self.transform = transform
        self.filter_images = []
        self.labels = []

        # Generate images for each item in the original dataset
        for idx in range(len(original_dataset)):
            # Get the class index for this image
            _, label = original_dataset[idx]
            class_name = idx_to_class[label]
            class_name = class_name[:-1]

            # Generate image based on the class name
            prompt = f"{prompt_name} {class_name}"
            new_image = generate_resized_image(prompt)

            # Store the image and its label
            self.filter_images.append(new_image)
            self.labels.append(label)

    def __len__(self):
        return len(self.original_dataset)

    def __getitem__(self, idx):
        # Get the image and its label
        image = self.filter_images[idx]
        label = self.labels[idx]

        # Apply transform if available
        if self.transform:
            image = self.transform(image)

        return image, label

"""### c. Create a cartoon dataset"""

cartoon_test_dataset = TestImageDataset(
    original_dataset=test_dataset,
    idx_to_class=idx_to_class,
    prompt_name="animated",
    transform=test_transforms
)

test_loader_cartoon = DataLoader(
    cartoon_test_dataset,
    batch_size=32,
    shuffle=False
)

data_iter = iter(test_loader_cartoon)
images, labels = next(data_iter)

# Get the first image
image = images[11]

# Convert from tensor to numpy and from [C, H, W] to [H, W, C]
image = image.permute(1, 2, 0).numpy()
image = image * 0.5 + 0.5  # Unnormalize

# Plot the image
plt.imshow(image)
plt.title(f"Animated Label: {labels[11].item()}")
plt.axis('off')
plt.show()

"""### d. Create a blur dataset"""

blur_test_dataset = TestImageDataset(
    original_dataset=test_dataset,
    idx_to_class=idx_to_class,
    prompt_name="blurry",
    transform=test_transforms
)

test_loader_blur = DataLoader(
    blur_test_dataset,
    batch_size=32,
    shuffle=False
)

data_iter = iter(test_loader_blur)
images, labels = next(data_iter)

# Get the first image
image = images[4]

# Convert from tensor to numpy and from [C, H, W] to [H, W, C]
image = image.permute(1, 2, 0).numpy()
image = image * 0.5 + 0.5  # Unnormalize

# Plot the image
plt.imshow(image)
plt.title(f"Blurry Label: {labels[4].item()}")
plt.axis('off')
plt.show()

"""# 3. CNN Network

### a. Define CNN Architecture
"""

class CNN(nn.Module):
    def __init__(self, seed=42):
        super(CNN, self).__init__()
        # seed.
        self.seed = torch.manual_seed(seed)

        # device.
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

        # Covolution layers.
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=4)         # (3,224,224)  -> (32,221,221)
        self.max1 = nn.MaxPool2d(kernel_size=2)                                       # (32,221,221) -> (32,110,110)
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)        # (32,110,110) -> (64,108,108)
        self.max2 = nn.MaxPool2d(kernel_size=2)                                       # (64,108,108) -> (64,54,54)
        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)        # (64,54,54)   -> (64,52,52)
        self.max3 = nn.MaxPool2d(kernel_size=2)                                       # (64,52,52)   -> (64,26,26)
        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)       # (64,26,26)   -> (128,24,24)
        self.max4 = nn.MaxPool2d(kernel_size=2)                                       # (128,24,24)  -> (128,12,12)

        # Linear layers.
        self.fc1 = nn.Linear(in_features=128 * 12 * 12, out_features=256)             # 18,432 -> 256
        self.fc2 = nn.Linear(in_features=256, out_features=128)                       # 256    -> 128
        self.fc3 = nn.Linear(in_features=128, out_features=3)                         # 256    -> 3 neurons in the output layer

        # moving device to GPU.
        self.to(self.device)

    def forward(self, state):
      x = self.max1(F.relu(self.conv1(state)))
      x = self.max2(F.relu(self.conv2(x)))
      x = self.max3(F.relu(self.conv3(x)))
      x = self.max4(F.relu(self.conv4(x)))
      x = x.view(x.size(0), -1)     # similar to flatten: reshapes the tensor from x (prev line) and flattens that. Feel free to change this if you guys like!!!
      x = F.relu(self.fc1(x))
      x = F.relu(self.fc2(x))
      return self.fc3(x)

"""### b. Initialize Model"""

model_cnn = CNN()

"""### c. Define Hyperparameters for Training"""

total_epochs = 10
loss = nn.CrossEntropyLoss()
learning_rate = 0.001
optimizer = optim.Adam(model_cnn.parameters(), lr = learning_rate)

"""### d. Training"""

def train(model, train_loader, criterion, optimizer, epochs, verbose=False):
  model.train()     # sets modulo to training mode.
  for epoch in range(1, epochs+1):
    running_loss = 0.0
    for animal_image, animal_label in train_loader:
      # put images and lables to GPU.
      animal_image = animal_image.to(model.device)
      animal_label = animal_label.to(model.device)

      # zero out the gradient (fresh start).
      optimizer.zero_grad()

      # forward propogation.
      output = model.forward(animal_image)
      loss = criterion(output, animal_label)

      # backward propogation.
      loss.backward()
      optimizer.step()

      running_loss += loss.item()
    #print(f"Epoch [{epoch}/{epochs}], Loss: {running_loss/len(train_loader):.4f}")

train(model_cnn, train_loader, loss, optimizer, epochs=total_epochs, verbose = False)

"""### e. Saving model"""

torch.save(model_cnn.state_dict(), "cnn_weights.pth")

"""# 4. Testing

### a. load model
"""

model_cnn = CNN()  # changed to load weights into the model
model_cnn.load_state_dict(torch.load("cnn_weights.pth"))
model_cnn.eval()

"""### b. Testing w/o TTT"""

def test(model, loader):
  model.eval()  # Set model to evaluation mode
  correct = 0
  total = 0
  all_labels = []
  all_predictions = []

  with torch.no_grad():  # No need to compute gradients during evaluation
      for images, labels in loader:
          # Move images and labels to the device
          images, labels = images.to(model.device), labels.to(model.device)

          # Forward pass
          outputs = model(images)
          _, predicted = torch.max(outputs, 1)
          total += labels.size(0)
          correct += (predicted == labels).sum().item()

          # Append true and predicted labels to lists
          all_labels.extend(labels.cpu().numpy())
          all_predictions.extend(predicted.cpu().numpy())

  print(f'Accuracy on test set: {100 * correct / total:.2f}%')
  return all_labels, all_predictions

# these are for the blur images!
all_labels, all_predictions = test(model_cnn, test_loader_blur)

all_labels_cartoon, all_predictions_cartoon = test(model_cnn, test_loader_cartoon)

"""### c. Testing w/ TTT"""

def test_ttt(model, imageFliter, loader_test):
    # initalize variables.
    model.eval()
    total = 0
    correct = 0
    all_labels = []
    all_preds = []

    # running through our NEW defined test loader.
    for images, labels in loader_test:
        images = images.to(model.device)
        labels = labels.to(model.device)

        # Assess whether the image is correctly predicted without TTT.
        with torch.no_grad():
            original_output = model(images)
            _, original_pred = torch.max(original_output, 1)

        # running TTT on each test image and label.
        for i in range(len(images)):
            total += 1

            # for effeciency purposes, skipping those who are already predicted correctly.
            if original_pred[i] == labels[i]:
                correct += 1
                all_labels.append(labels[i].item())
                all_preds.append(original_pred[i].item())
                continue

            # --- TTT block!!! ---
            label = labels[i].item()
            class_name = dataset.classes[label]
            class_name = class_name[:-1]

            # this is how we used to create our mini training set; left it in to show our progress
            """
            image_tensor = images[i].cpu()
            image_pil = transforms.ToPILImage()(image_tensor)
            transformer = ImageTransformation(image_pil)

            # generate set of "training" images.
            image_transformations = [
                transformer.gaussian_blur(0.1),
                transformer.brighten(1.2),
                transformer.darken(0.6),
            ]"""

            # creating our mini training set + eval image.
            gpt_image_transformations = []
            evaluate_img = generate_resized_image(f"an image of a {imageFliter} {class_name}")
            time.sleep(1)
            for _ in range(3):
                image_pil = generate_resized_image(f"an image of a {imageFliter} {class_name}")
                gpt_image_transformations.append(image_pil)
                time.sleep(1)   # check the libraries section why I use this command :)

            # preprocess - convert to tensors.
            train_tensors = [transforms.ToTensor()(img).unsqueeze(0) for img in gpt_image_transformations]
            train_images = torch.cat(train_tensors)
            dummy_labels = torch.full((len(gpt_image_transformations),), label, dtype=torch.long)

            # turn the train_images into dataloaders.
            ttt_dataset = torch.utils.data.TensorDataset(train_images, dummy_labels)
            train_loader_ttt = DataLoader(ttt_dataset, batch_size=3, shuffle=True)

            # create an instance of our model - doing this by defining a new model and copying over the previous used parameters.
            model_instance = CNN()
            model_instance.load_state_dict(model.state_dict())
            model_instance.to(model.device)

            # define "new" TTT hyperparameters.
            optimizer_ttt = optim.Adam(model_instance.parameters(), lr=0.001)
            train(model_instance, train_loader_ttt, loss, optimizer_ttt, epochs=1, verbose=False)

            # Re-run prediction!
            model_instance.eval()
            with torch.no_grad():
                #updated_output = model_instance(images[i].unsqueeze(0))     # CHEATING! CAN'T RE-RUN ON THE ORIGINAL PREDICTION.
                eval_tensor = transforms.ToTensor()(evaluate_img).unsqueeze(0).to(model.device)   # we need to evaluate on the eval image we created!!
                updated_output = model_instance(eval_tensor)
                _, updated_pred = torch.max(updated_output, 1)

                # hopefully it's a yay!
                if updated_pred.item() == label:
                    correct += 1

                all_labels.append(label)
                all_preds.append(updated_pred.item())

    accuracy = 100 * sum([l == p for l, p in zip(all_labels, all_preds)]) / len(all_labels)
    print(f"Final TTT-Enhanced Accuracy: {accuracy:.2f}%")
    return all_labels, all_preds

"""### d. Calling with blurry and cartoon images."""

ttt_labels_blur, ttt_preds_blur = test_ttt(model_cnn, "blur", test_loader_blur)

ttt_labels_cartoon, ttt_preds_cartoon = test_ttt(model_cnn, "animated", test_loader_cartoon)

"""# 4. CNN Evaluation

### a. Confusion Matrix
"""

cm = confusion_matrix(all_labels, all_predictions)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=dataset.classes, yticklabels=dataset.classes)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Without TTT Confusion Matrix')
plt.show()

cm = confusion_matrix(ttt_labels_blur, ttt_preds_blur)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=dataset.classes, yticklabels=dataset.classes)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('With TTT Confusion Matrix')
plt.show()

cm = confusion_matrix(ttt_labels_cartoon, ttt_preds_cartoon)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=dataset.classes, yticklabels=dataset.classes)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('With TTT Confusion Matrix (Cartoon)')
plt.show()

"""### b. Recall"""

recall = recall_score(all_labels, all_predictions, average='macro')
print(f"Without TTT Recall: {recall}")

recall_ttt = recall_score(ttt_labels_blur, ttt_preds_blur, average='macro')
print(f"TTT Recall: {recall_ttt}")

recall_ttt = recall_score(ttt_labels_cartoon, ttt_preds_cartoon, average='macro')
print(f"TTT Recall: {recall_ttt}")

"""### c. Precision"""

precision = precision_score(all_labels, all_predictions, average='macro')
print(f"Without TTT Precision: {precision}")

precision_ttt = precision_score(ttt_labels_blur, ttt_preds_blur, average='macro')
print(f"TTT Precision: {precision_ttt}")

precision_ttt = precision_score(ttt_labels_cartoon, ttt_preds_cartoon, average='macro')
print(f"TTT Precision: {precision_ttt}")

"""### d. F1-Score"""

f1score = f1_score(all_labels, all_predictions, average='macro')
print(f"Without TTT F1-Score: {f1score}")

f1score_ttt = f1_score(ttt_labels_blur, ttt_preds_blur, average='macro')
print(f"TTT F1-Score: {f1score_ttt}")

f1score_ttt = f1_score(ttt_labels_cartoon, ttt_preds_cartoon, average='macro')
print(f"TTT F1-Score: {f1score_ttt}")